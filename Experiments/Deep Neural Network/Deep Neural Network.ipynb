{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We devided the training data to 2 different datasets.\n",
    "- Training data: The training data will be used to train the model and recalculate the weights \n",
    "- Validation data: The validation data will be used to see the network's success on new data.\n",
    "\n",
    "We use this method in order to prevent over fitting our model. \n",
    "The success of our model will be messured by It's preformmance on the Validation data.\n",
    "\n",
    "* We will set rotation in order to create a larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "                               rotation_range=30,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.8, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='reflect',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5])\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                               rotation_range=30,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.8, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='reflect',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5])\n",
    "\n",
    "image_size = (128,128)\n",
    "batch_size = 10\n",
    "\n",
    "training_data_dir = r'C:\\Users\\yonba\\OneDrive\\Desktop\\Education\\Semester_A_2019\\Image_Processing\\PhotosDataSet\\_Data'\n",
    "validation_data_dir = r'C:\\Users\\yonba\\OneDrive\\Desktop\\Education\\Semester_A_2019\\Image_Processing\\PhotosDataSet\\_Test'\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(training_data_dir,\n",
    "                                                 target_size=image_size,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                        validation_data_dir,\n",
    "                                         target_size=image_size,\n",
    "                                         color_mode='rgb',\n",
    "                                        class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some of the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    image = x_batch[i]\n",
    "    image= image.astype(int)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "\n",
    "amountOfClasses = 100;\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flatening the data\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamOptimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "             optimizer= adamOptimizer,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "print(step_size_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Loss and Accuracy history callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LossAccHisotry(Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.loss_history = []\n",
    "        self.accuracy_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.val_accuracy_history = []\n",
    "        \n",
    "    #def on_batch_end(self,batch, logs={}):\n",
    "        #self.loss_history.append(logs.get('loss'))\n",
    "        #self.accuracy_history.append(logs.get('acc'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_loss_history.append(logs.get('val_loss'))\n",
    "        self.val_accuracy_history.append(logs.get('val_acc'))\n",
    "        self.loss_history.append(logs.get('loss'))\n",
    "        self.accuracy_history.append(logs.get('acc'))\n",
    "    \n",
    "history = LossAccHisotry()## Setting the network saving time periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the network saving time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "networkfileName = \"resnet_exp1_{}.h5\".format(int(time.time()))\n",
    "checkpoint = ModelCheckpoint(networkfileName, monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumberOfEpochs = 10;\n",
    "ValidationSplits = 0.1;\n",
    "\n",
    "model.fit(x_batch, y_batch, batch_size=step_size_train, epochs = NumberOfEpochs, validation_split=ValidationSplits, callbacks=[history, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = range(0, len(history.val_loss_history))\n",
    "plt.plot(x, history.val_loss_history)\n",
    "plt.plot(x, history.val_accuracy_history)\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Validation')\n",
    "plt.legend(['loss', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plts\n",
    "x = range(0, len(history.loss_history))\n",
    "plt.plot(x, history.loss_history)\n",
    "plt.plot(x, history.accuracy_history)\n",
    "plt.xlabel('epoxhs')\n",
    "plt.title('Train')\n",
    "plt.legend(['loss', 'accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
